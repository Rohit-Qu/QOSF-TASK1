All the graphs for different number of layer shows that AdagradOptimizeris better than GradientOptimizer as it remains stable, as the cost approaches a 
saturation level  and the number of layer increases. 
Also, around 400 iteration the slope seems to flatten. Thus 500 iteration is optimal.
